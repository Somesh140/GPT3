{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Somesh140/GPT3/blob/main/1_Dataset_creation_with_GPT_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNhrij2dTZLa",
        "outputId": "cdcf2b02-8fc0-4bcd-fc1f-5b1d3e237296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --quiet openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjeONNjIRjut",
        "outputId": "b6c15215-4654-48de-ff8c-2e23a8e64358"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter OpenAI API key:··········\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import openai\n",
        "import getpass\n",
        "\n",
        "openai.api_key = getpass.getpass(prompt='Enter OpenAI API key:')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfek40BqadTE"
      },
      "source": [
        "## Generate paraphrases with GPT-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rjPpgpnoUDZE"
      },
      "outputs": [],
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci-instruct-beta\",\n",
        "  prompt=\"I am a diverse paraphrasing expert. I will generate many random pairs of original and paraphrased sentences.\\n\\nHere are a few:\\n\\noriginal: Once, a group of frogs was roaming around the forest in search of water.\\nparaphrase:  A gang of frogs was roaming about the woods in search of water once more.\\n\\noriginal:\",\n",
        "  temperature=0.7,\n",
        "  max_tokens=100,\n",
        "  top_p=0.9,\n",
        "  frequency_penalty=0.5,\n",
        "  presence_penalty=0.6,\n",
        "  stop=[\"original\"]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-oxyfbyWneP",
        "outputId": "cdf2254e-9f22-49e6-8801-4f60b7e5a693"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": null,\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \" The family had been given the best seats.\\nparaphrase: The family had been gifted with the best seats.\"\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1685621140,\n",
            "  \"id\": \"cmpl-7MbLgOX9CJcQRyT4sMjNIvBqYq3QM\",\n",
            "  \"model\": \"davinci-instruct-beta\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 24,\n",
            "    \"prompt_tokens\": 76,\n",
            "    \"total_tokens\": 100\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mGSma8zUiiN",
        "outputId": "9ce6dbf4-5ae7-4949-9f7f-bdac4a4b02c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "The family had been given the best seats.\n",
            "The family had been gifted with the best seats.\n"
          ]
        }
      ],
      "source": [
        "output_string = response['choices'][0]['text'].strip()\n",
        "output_modified = output_string.replace(\"paraphrase:\",\"\")\n",
        "original_sentence, paraphrased_sentence = output_modified.split('\\n')\n",
        "original_sentence = original_sentence.strip()\n",
        "paraphrased_sentence = paraphrased_sentence.strip()\n",
        "print (\"-----------------------------------------------------------------------\")\n",
        "print (original_sentence)\n",
        "print (paraphrased_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNQfo95RanvC"
      },
      "source": [
        "## Streamlit Dataset Creator UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksyIFOFsVXrm",
        "outputId": "8d4f00ea-9ba2-4999-9808-bb72673af1ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.8/82.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 2.2.4 requires click>=8.0, but you have click 7.1.2 which is incompatible.\n",
            "pip-tools 6.13.0 requires click>=8, but you have click 7.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --quiet streamlit==1.1.0  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaEzki-EbFwV",
        "outputId": "dadb4305-da81-490a-8fc8-935f24b7c424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "import json\n",
        "import streamlit.components.v1 as components\n",
        "import os\n",
        "import openai\n",
        "import getpass\n",
        "import pandas as pd\n",
        "\n",
        "# openai.api_key = getpass.getpass(prompt='Enter OpenAI API key:')\n",
        "openai.api_key  = st.text_input(\"OpenAI API Key\", '',type=\"password\")\n",
        "\n",
        "# st.write('# Moviepro.ai')\n",
        "st.markdown(\"<h1 style='text-align: center; color: blue;'>Paraphrase Dataset Generator</h1>\", unsafe_allow_html=True)\n",
        "st.write(\"## Create paraphrase dataset, powered by GPT-3.\")\n",
        "\n",
        "st.write(\"\")\n",
        "if \"original\" not in st.session_state:\n",
        "    st.session_state.original = \"\"\n",
        "if \"paraphrase\" not in st.session_state:\n",
        "    st.session_state.paraphrase = \"\"\n",
        "if \"df\" not in st.session_state:\n",
        "    st.session_state.df = pd.DataFrame(columns=['original','paraphrase'])\n",
        "\n",
        "def getparaphrase():\n",
        "  response = openai.Completion.create(\n",
        "  engine=\"davinci-instruct-beta\",\n",
        "  prompt=\"I am a diverse paraphrasing expert. I will generate many random pairs of original and paraphrased sentences.\\n\\nHere are a few:\\n\\noriginal: Once, a group of frogs was roaming around the forest in search of water.\\nparaphrase:  A gang of frogs was roaming about the woods in search of water once more.\\n\\noriginal:\",\n",
        "  temperature=0.7,\n",
        "  max_tokens=100,\n",
        "  top_p=0.9,\n",
        "  frequency_penalty=0.5,\n",
        "  presence_penalty=0.6,\n",
        "  stop=[\"original\"]\n",
        "  )\n",
        "  output_string = response['choices'][0]['text'].strip()\n",
        "  output_modified = output_string.replace(\"paraphrase:\",\"\")\n",
        "  original_sentence, paraphrased_sentence = output_modified.split('\\n')\n",
        "  st.session_state.original = original_sentence.strip()\n",
        "  st.session_state.paraphrase = paraphrased_sentence.strip()\n",
        "\n",
        "def addtodb():\n",
        "  data = {\n",
        "    'original': st.session_state.original,\n",
        "    'paraphrase': st.session_state.paraphrase\n",
        "    }\n",
        "\n",
        "  st.session_state.df = st.session_state.df.append(data, ignore_index=True)\n",
        "  st.write (st.session_state.df.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "st.button(\"Generate paraphrases\",on_click=getparaphrase)\n",
        "st.button(\"Add to Database\",on_click=addtodb)\n",
        "\n",
        "st.write(\"**Original:** \"+st.session_state.original)\n",
        "st.write(\"**Paraphrase:** \"+st.session_state.paraphrase)\n",
        "st.dataframe(st.session_state.df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIbYJ_e2d08F",
        "outputId": "f026d2c6-e36e-43d0-90d2-0a57a38cd666"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-01 12:14:36.968 INFO    numexpr.utils: NumExpr defaulting to 2 threads.\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.142.213.118:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\n",
            "  \u001b[34m\u001b[1mA new version of Streamlit is available.\u001b[0m\n",
            "\n",
            "  See what's new at https://discuss.streamlit.io/c/announcements\n",
            "\n",
            "  Enter the following command to upgrade:\n",
            "  \u001b[34m$\u001b[0m \u001b[1mpip install streamlit --upgrade\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.883s\n",
            "your url is: https://loose-files-sort.loca.lt\n",
            "/content/app.py:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  st.session_state.df = st.session_state.df.append(data, ignore_index=True)\n",
            "/content/app.py:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  st.session_state.df = st.session_state.df.append(data, ignore_index=True)\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "tduIrrvwbntn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ae1775e-5f92-47b2-a4de-5a715ae465d8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.142.213.118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnPEr4mr4N4V",
        "outputId": "5d2c5429-c6c5-41d3-90ba-c7ba5226be42"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.142.213.118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_5QKFfhB4TzU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}